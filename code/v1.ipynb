{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-v\", \"--video\", type=str,\n",
    "\thelp=\"path to input video file\")\n",
    "ap.add_argument(\"-t\", \"--tracker\", type=str, default=\"mil\",\n",
    "\thelp=\"OpenCV object tracker type\")\n",
    "args = vars(ap.parse_known_args()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the OpenCV version info\n",
    "(major, minor) = cv2.__version__.split(\".\")[:2]\n",
    "# if we are using OpenCV 3.2 OR BEFORE, we can use a special factory\n",
    "# function to create our object tracker\n",
    "if int(major) == 3 and int(minor) < 3:\n",
    "\ttracker = cv2.Tracker_create(args[\"tracker\"].upper())\n",
    "# otherwise, for OpenCV 3.3 OR NEWER, we need to explicity call the\n",
    "# approrpiate object tracker constructor:\n",
    "else:\n",
    "\t# initialize a dictionary that maps strings to their corresponding\n",
    "\t# OpenCV object tracker implementations\n",
    "\tOPENCV_OBJECT_TRACKERS = {\n",
    "\t\t\"csrt\": cv2.TrackerCSRT_create,\n",
    "\t\t\"kcf\": cv2.TrackerKCF_create,\n",
    "\t\t# \"boosting\": cv2.TrackerBoosting_create,\n",
    "\t\t\"mil\": cv2.TrackerMIL_create,\n",
    "\t\t# \"tld\": cv2.TrackerTLD_create,\n",
    "\t\t# \"medianflow\": cv2.TrackerMedianFlow_create,\n",
    "\t\t# \"mosse\": cv2.TrackerMOSSE_create\n",
    "\t}\n",
    "\t# grab the appropriate object tracker using our dictionary of\n",
    "\t# OpenCV object tracker objects\n",
    "\ttracker = OPENCV_OBJECT_TRACKERS[args[\"tracker\"]]()\n",
    "# initialize the bounding box coordinates of the object we are going\n",
    "# to track\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mil\n",
    "tld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over frames from the video stream\n",
    "initBB = None\n",
    "vs = cv2.VideoCapture(\"test_4.mp4\")\n",
    "fps = vs.get(5)\n",
    "while True:\n",
    "\t# grab the current frame, then handle if we are using a\n",
    "\t# VideoStream or VideoCapture object\n",
    "\tframe = vs.read()[1]\n",
    "\tif frame is None:\n",
    "\t\tbreak\n",
    "\t# resize the frame (so we can process it faster) and grab the\n",
    "\t# frame dimensions\n",
    "\t(H, W) = frame.shape[:2]\n",
    "\t\t# check to see if we are currently tracking an object\n",
    "\tif initBB is not None:\n",
    "\t\t# grab the new bounding box coordinates of the object\n",
    "\t\t(success, box) = tracker.update(frame)\n",
    "\t\t# check to see if the tracking was a success\n",
    "\t\tif success:\n",
    "\t\t\t(x, y, w, h) = [int(v) for v in box]\n",
    "\t\t\tcv2.rectangle(frame, (x, y), (x + w, y + h),\n",
    "\t\t\t\t(0, 255, 0), 2)\n",
    "\t\t# update the FPS counter\n",
    "\t\tfps.update()\n",
    "\t\tfps.stop()\n",
    "\t\t# initialize the set of information we'll be displaying on\n",
    "\t\t# the frame\n",
    "\t\tinfo = [\n",
    "\t\t\t(\"Tracker\", args[\"tracker\"]),\n",
    "\t\t\t(\"Success\", \"Yes\" if success else \"No\"),\n",
    "\t\t\t(\"FPS\", \"{:.2f}\".format(fps.fps())),\n",
    "\t\t]\n",
    "\t\t# loop over the info tuples and draw them on our frame\n",
    "\t\tfor (i, (k, v)) in enumerate(info):\n",
    "\t\t\ttext = \"{}: {}\".format(k, v)\n",
    "\t\t\tcv2.putText(frame, text, (10, H - ((i * 20) + 20)),\n",
    "\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\t\t# show the output frame\n",
    "\tcv2.imshow(\"Frame\", frame)\n",
    "\tkey = cv2.waitKey(1) & 0xFF\n",
    "\t# if the 's' key is selected, we are going to \"select\" a bounding\n",
    "\t# box to track\n",
    "\tif key == ord(\"s\"):\n",
    "\t\t# select the bounding box of the object we want to track (make\n",
    "\t\t# sure you press ENTER or SPACE after selecting the ROI)\n",
    "\t\tinitBB = cv2.selectROI(\"Frame\", frame, fromCenter=False,\n",
    "\t\t\tshowCrosshair=True)\n",
    "\t\t# start OpenCV object tracker using the supplied bounding box\n",
    "\t\t# coordinates, then start the FPS throughput estimator as well\n",
    "\t\ttracker.init(frame, initBB)\n",
    "\t\tfps = FPS().start()\n",
    "\t\t\t# if the `q` key was pressed, break from the loop\n",
    "\telif key == ord(\"q\"):\n",
    "\t\tbreak\n",
    "vs.release()\n",
    "# close all windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('musa_research')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a279928d780aab837ac5d19f9bba0fe4deeeffbe3465d728df509f97f369c0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
